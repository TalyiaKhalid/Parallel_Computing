{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Version of the Sequential Code (With Race Conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager, Lock, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the images\n",
    "input_folder = 'cars'  # Replace with the path to your folder\n",
    "output_folder = 'cars_filtered'  # Replace with the path to save filtered images\n",
    "\n",
    "# Creating the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process rows (done in parallel)\n",
    "def process_row(row_index, image, filter_kernel, filter_size, height, width, shared_dict):\n",
    "\n",
    "    output_row = np.zeros(width, dtype=np.float32)\n",
    "    for j in range(width):\n",
    "        weighted_sum = 0.0\n",
    "        for k in range(filter_size):\n",
    "            for l in range(filter_size):\n",
    "                row = row_index + k - filter_size // 2\n",
    "                col = j + l - filter_size // 2\n",
    "                if 0 <= row < height and 0 <= col < width:\n",
    "                    weighted_sum += image[row, col] * filter_kernel[k, l]\n",
    "        output_row[j] = weighted_sum\n",
    " \n",
    "    # Incrementing the value of row processed\n",
    "    shared_dict[\"row_processed\"] += 1    \n",
    "    \n",
    "    return output_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function with parallel processing of rows using joblib\n",
    "def parallel_process(image, shared_dict):\n",
    "\n",
    "    # Preparing for parallel processing\n",
    "    height, width = image.shape\n",
    "\n",
    "    filter_kernel = np.array([[0.1, 0.2, 0.1],\n",
    "                              [0.2, 0.1, 0.2],\n",
    "                              [0.1, 0.2, 0.1]], dtype=np.float32)\n",
    "    \n",
    "    filter_size = filter_kernel.shape[0]\n",
    "\n",
    "    # Parallelizing the row processing using joblib\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_row)(i, image, filter_kernel, filter_size, height, width, shared_dict) for i in range(height))\n",
    "\n",
    "    # Reconstructing the output image from the processed rows\n",
    "    output_image = np.array(results, dtype=np.float32)\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and save each image (Done in parallel)\n",
    "def process_image(image_path, shared_dict):\n",
    "    \n",
    "    # Reading the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "    if image is None:\n",
    "        print(f\"Could not open or find the image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Applying Gaussian Blur\n",
    "    blurred_image = cv2.GaussianBlur(image, (3,3), 0)\n",
    "        \n",
    "    # Computing the elevation map using Sobel operator for edge detection\n",
    "    sobel_x = cv2.Sobel(blurred_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(blurred_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        \n",
    "    # Combining the gradients to obtain the magnitude of the gradient\n",
    "    magnitude_gradient = cv2.magnitude(sobel_x, sobel_y)\n",
    "    \n",
    "    # Normalizing the image to a range between 0 and 1 (floating-point operations)\n",
    "    image = magnitude_gradient.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Applying custom filter operation\n",
    "    output_image = parallel_process(image,shared_dict)\n",
    "    \n",
    "    # Clipping the output to stay in the range [0, 1]\n",
    "    output_image = np.clip(output_image, 0.0, 1.0)\n",
    "\n",
    "    # Converting the processed image back to 8-bit (0-255)\n",
    "    processed_image = (output_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Saving the processed image\n",
    "    output_image_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_image_path, processed_image)\n",
    "\n",
    "    # Incrementing the value of image processed\n",
    "    shared_dict[\"processed_image_count\"] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken by the execution of this code for all images using Joblib: 49.20s\n",
      "Processed Images: 200\n",
      "Processed Rows: 2421\n"
     ]
    }
   ],
   "source": [
    "# List of image paths to process\n",
    "image_paths = [os.path.join(input_folder, filename) for filename in os.listdir(input_folder)\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "\n",
    "# Manager provides a way to share data safely between processes by allowing access to a shared object\n",
    "with Manager() as manager:\n",
    "\n",
    "        shared_dict = manager.dict({\"processed_image_count\": 0, \"row_processed\": 0})  \n",
    "        Start_time = time.time()\n",
    "\n",
    "        # Parallelizing the image processing using joblib\n",
    "        Parallel(n_jobs=-1)(delayed(process_image)(image_path,shared_dict) for image_path in image_paths)\n",
    "\n",
    "        # Printing\n",
    "        print(f\"Total time taken by the execution of this code for all images using Joblib: {time.time() - Start_time:.2f}s\")\n",
    "        print(f\"Processed Images: {shared_dict['processed_image_count']}\")\n",
    "        print(f\"Processed Rows: {shared_dict['row_processed']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
